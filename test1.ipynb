{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Приветствую того, кто читает этот код.В качестве научной работы в университете я занимаюсь спайковыми нейронными сетями. Основной библиотекой является brian2. Так как эта область довольно новая, каких-то готовых хороших алгоритмов для решения определенных задач практически нет, поэтому многое приходится делать методом проб и ошибок, а в этом очень сильно помогает визуализация данных и наш любимый matplotlib. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В классических нейронных сетях простейшей задачей, с которой начинают новички является классификация mnist, но для спайковых сетей эта задача пока довольно сложная, поэтому в данной работе я покажу их работу на примере двухклассовой классификации датасета digits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кратко о спайковых нейронных сетях. Спайковый нейрон взят из биологии и представляет из себя элемент, который получает импульсы тока и накапливает потенциал на мембране. Когда потенциал превышает определенное значение нейрон передает импульс(спайк) к другим нейронам через связи, собственно веса связей между нейронами и подбираются в процессе обучения. В отличии от классических нейронных сетей, спайковые сети принимают на вход не одну картинку, а ряд из одной картинки, то есть они как бы смотрят на картинку втечение некоторого времени, заряжая мембраны нейронов. Так же между нейронами последнего слоя можно организовать конкуренцию за ток от входных нейронов, это позволяет ускорить обучение. Архитектура сети очень простая: входной слой по нейрону на каждый пиксель картинки и выходной слой 2 нейрона."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from brian2 import *\n",
    "#%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Loading dataset Normalizing data to [0,1]\n",
    "digits=datasets.load_digits(2)\n",
    "data, y = (digits.images/16),digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdEAAAFgCAYAAADkVUNLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSIgCQJEQBYCi/wXO/95w6l6ErAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feec156ed10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure('data')\n",
    "for j in np.arange(int(16)):\n",
    "    subplot(4, 4, j+1)\n",
    "    imshow(data[j+100].reshape(8, 8), cmap='winter', interpolation='None')\n",
    "    axis('off')\n",
    "    #print(y[j+100])\n",
    "show()\n",
    "\n",
    "data = data.reshape(-1, 64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задаем правила обучения сети и значения гиперпараметров. Спайковые сети описываются дифференциальными и алгебраическими уравнениями, определяющими взаимодействие нейронов и частоту спайкования, ещё тут довольно много гиперпараметров, которые нужно подбирать для нормального обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_scope()\n",
    "\n",
    "n_input_width = 8.\n",
    "n_input_height = n_input_width\n",
    "n_input = n_input_width* n_input_height\n",
    "\n",
    "n_hidden = 2\n",
    "\n",
    "time_step = 0.1 * ms\n",
    "alpha = 10 * ms\n",
    "beta = 100 * ms\n",
    "tau = 10*ms\n",
    "tau_I = 15*ms\n",
    "tau_h = 50*ms\n",
    "\n",
    "wmax = 1.0\n",
    "c_inp = 0.2\n",
    "c_neg = 1.7  #8.8\n",
    "lr = 0.05\n",
    "lr_n = 0.01\n",
    "decay = 0.001\n",
    "\n",
    "eqs_input_neuron = '''\n",
    "rates : Hz\n",
    "da/dt = -a/alpha : 1\n",
    "dtheta/dt = -theta/beta : 1\n",
    "diff = a - theta: 1\n",
    "train : 1\n",
    "'''\n",
    "\n",
    "eqs_hidden_neuron = '''\n",
    "dv/dt = (-v+I)/tau : 1 (unless refractory)\n",
    "dI_inp/dt = -I_inp/tau_I :1\n",
    "dI_neg/dt = -I_neg/tau_I :1\n",
    "I_teacher : 1\n",
    "I = I_inp + I_neg + I_teacher :1\n",
    "da/dt = -a/alpha : 1\n",
    "dtheta/dt = -theta/beta : 1\n",
    "diff = a - theta: 1\n",
    "dhold/dt = -hold/tau_h : 1\n",
    "train : 1\n",
    "'''\n",
    "\n",
    "reset_hidden = '''\n",
    "v = 0\n",
    "hold += 0.1 * n_hidden\n",
    "'''\n",
    "\n",
    "eqs_input_syn = '''\n",
    "w : 1\n",
    "'''\n",
    "\n",
    "# equations that describe changes if presynaptic spike of the forward-oriented synapse of input layer occures\n",
    "eqs_input_pre = '''\n",
    "I_inp_post += w * c_inp\n",
    "a_pre += 1./n_hidden *1*ms/(alpha)\n",
    "theta_pre += 1./n_hidden *1*ms/(beta)\n",
    "'''\n",
    "\n",
    "# equations that describe changes if postsynaptic spike of the forward synapse occures\n",
    "eqs_input_post = '''\n",
    "a_post += 1./n_input *1*ms/(alpha)\n",
    "theta_post += 1./n_input *1*ms/(beta)\n",
    "w = clip(w + train_pre * (-decay + lr*diff_pre), 0, wmax)\n",
    "'''\n",
    "\n",
    "eqs_neg_syn = '''\n",
    "w : 1\n",
    "'''\n",
    "\n",
    "# equations that describe changes if presynaptic spike of the forward-oriented synapse of input layer occures\n",
    "eqs_neg_pre = '''\n",
    "I_neg_post += w * c_neg\n",
    "'''\n",
    "\n",
    "#w = clip(w + train_pre*(+decay - lr_n * diff_post), -wmax, 0)\n",
    "\n",
    "# equations that describe changes if postsynaptic spike of the forward synapse occures\n",
    "eqs_neg_post = '''\n",
    "w = clip(w + train_pre*(-lr_n*diff_pre), -wmax, 0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем значения параметров сети, нейронные группы и связи между нейронами."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "im here\n",
      "now here\n"
     ]
    }
   ],
   "source": [
    "P = NeuronGroup(n_input, eqs_input_neuron, threshold='rand()<rates*dt', method='linear', refractory=2*ms, dt = time_step, name='P')\n",
    "P.rates = [k*250*Hz for k in data[0]]\n",
    "P.train = np.ones_like(P.train)\n",
    "P.a = np.random.rand(len(P))*0.5\n",
    "P.theta = np.random.rand(len(P))*0.5\n",
    "\n",
    "StateMonitorP = StateMonitor(P, ['rates', 'a', 'theta', 'diff'], record=True)\n",
    "\n",
    "G = NeuronGroup(n_hidden, eqs_hidden_neuron, method='linear', threshold='v > hold', reset=reset_hidden, refractory=2*ms, dt=time_step, name = 'G')\n",
    "G.train = np.ones_like(G.train)\n",
    "G.a = np.random.rand(len(G))*0.5\n",
    "G.theta = np.random.rand(len(G))*0.5     \n",
    "G.hold = np.ones_like(G.hold) * 3.\n",
    "\n",
    "StateMonitorG = StateMonitor(G, ['a', 'I', 'diff', 'I_inp', 'I_neg', 'hold'], record=True)\n",
    "\n",
    "S = Synapses(P, G, eqs_input_syn, on_pre=eqs_input_pre, on_post=eqs_input_post, dt=time_step)\n",
    "S.connect()\n",
    "S.w = np.random.rand(len(S))\n",
    "\n",
    "StateMonitorS = StateMonitor(S, ['w'], record=True)\n",
    "\n",
    "S_neg = Synapses(G, G, eqs_neg_syn, on_pre=eqs_neg_pre, on_post=eqs_neg_post, dt=time_step)\n",
    "S_neg.connect('i!=j')\n",
    "#S_neg.w = np.random.rand(len(S_neg)) * (-1.)\n",
    "S_neg.w = np.ones_like(S_neg.w) * (-1.)\n",
    "\n",
    "StateMonitorS_neg = StateMonitor(S_neg, ['w'], record=True)\n",
    "print \"im here\"\n",
    "predictions = []\n",
    "labels = []\n",
    "counter = 0\n",
    "train = 1\n",
    "@network_operation(dt=50*ms)\n",
    "def update_input():\n",
    "    global counter\n",
    "    global train\n",
    "    if counter % 2 == 0:\n",
    "        \n",
    "        #if counter:\n",
    "         #   predictions.append(np.argmax(np.mean(StateMonitorG.a[:,-50:], axis=1)))\n",
    "        \n",
    "        index = np.random.randint(1,349)\n",
    "        P.rates = [k*250*Hz for k in data[index]]\n",
    "        if train:\n",
    "            G.I_teacher = np.zeros_like(G.I_teacher)\n",
    "            G.I_teacher[int(y[index])] = 100.0\n",
    "\n",
    "        labels.append(int(y[index]))\n",
    "    else:\n",
    "        P.rates = np.zeros_like(P.rates)\n",
    "        G.I_teacher = np.zeros_like(G.I_teacher)\n",
    "        predictions.append(np.argmax(np.mean(StateMonitorG.a[:,-50:], axis=1)))\n",
    "    counter += 1\n",
    "\n",
    "run(10000*ms)\n",
    "print \"now here\"\n",
    "#add last prediction\n",
    "#predictions.append(np.argmax(np.mean(StateMonitorG.a[:,-50:], axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "20000 милисекунд обучали сеть, посчитаем точность на трейне. Все хорошо, это единица!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print accuracy_score(predictions, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на веса нейронов входного слоя. Они действительно становятся похожи на 1 и 0 соответственно. Это здорово!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAJQAAAEiCAYAAAAf2PsIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAPYQAAD2EBqD+naQAABPhJREFUeJzt3TuLpEUUgOFqLysG3hJFDYxUBEFMTQzERDRSMPAXiKyB\nYLAieAH/gOaCGAmCZpqKGxoZG7hioCAieEPW3TbeQBxOv93TDs8Tz6G+4J0amK6ub7PdbhdUrjvt\nB+BsERQpQZESFClBkRIUKUGREhQpQZG6Yd8LbDbr3bXW+X2vc63hf/+3bx10ubXWWte9ucPw4Wy3\na3OSn7NDkRIUKUGREhQpQZESFClBkRIUKUGREhQpQZESFClBkdr7aYPdDD/Gv/L2QZdbX90zHFxr\n/T084XDDG/M198gORUpQpARFSlCkBEVKUKQERUpQpARFSlCkBEVKUKQEReoApw12+OL/wz8edsn7\nX57NfX/rcMG11h/vzObu+2U2d+n22dwJ2aFICYqUoEgJipSgSAmKlKBICYqUoEgJipSgSAmKlKBI\nHffdBo9fms39Pfw9+e622dzVE71koPX5h7O5h/b7Ugs7FClBkRIUKUGREhQpQZESFClBkRIUKUGR\nEhQpQZESFClBkTru4yv3/DqbO3elfY7/cv3V+ex2ePTl7t/ma+6RHYqUoEgJipSgSAmKlKBICYqU\noEgJipSgSAmKlKBICYrUAU4b7HCRxOtPzOYuXJyvOTE9MbDWWpvhe0RO44KOE7BDkRIUKUGREhQp\nQZESFClBkRIUKUGREhQpQZESFClBkTruuw2GH8Svn2+ezb332Wzuzt9nc2vNTyrc+8p8zT2yQ5ES\nFClBkRIUKUGREhQpQZESFClBkRIUKUGREhQpQZE67tMGU3e9Opu7/PZsbnoqYq21Hjw/m/vzxh0W\n3R87FClBkRIUKUGREhQpQZESFClBkRIUKUGREhQpQZESFKlDnDb4eq31yQHW4Qhstttdzl7AtfzJ\nIyUoUoIiJShSgiIlKFKCIiUoUoIiJShSgiIlKFKCIiUoUoIiJShSgiIlKFKCIiUoUoIitfevUW02\n65m11mOz6eE3cs5dmc1d+HI299rF2dxaa73/6Gzuxafnaw5st+vCSX7uEN/Le3KtNbzqliNyoqD8\nySMlKFKCIiUoUoIiJShSgiIlKFKCIiUoUoIiJShSgiJ15O8c3szGLl8/m3vji9ncLvfevvTUDsPH\nxw5FSlCkBEVKUKQERUpQpARFSlCkBEVKUKQERUpQpARF6shPGww/xn/gp9nc8HDDTransej+2KFI\nCYqUoEgJipSgSAmKlKBICYqUoEgJipSgSAmKlKBIHflpg6EPPp3NTe8o2OXEwC73IhwhOxQpQZES\nFClBkRIUKUGREhQpQZESFClBkRIUKUGREhSps3na4IVnZ3PfvDtccJcjA+42gH8lKFKCIiUoUoIi\nJShSgiIlKFKCIiUoUoIiJShSgiIlKFJn8/jKWbuB4n/EDkVKUKQERUpQpARFSlCkBEVKUKQERUpQ\npARFSlCkBEXqbJ42uOWv036Ck/v4o9ncc8+3zxGxQ5ESFClBkRIUKUGREhQpQZESFClBkRIUKUGR\nEhQpQZE6m6cNvr1jNje9EuHqDq/XeOSH4eDwYW+6MlzvZKnYoUgJipSgSAmKlKBICYqUoEgJipSg\nSAmKlKBICYqUoEhttltvHaBjhyIlKFKCIiUoUoIiJShSgiIlKFKCIiUoUoIiJShSgiIlKFKCIiUo\nUoIiJShSgiIlKFKCIiUoUoIiJShSgiIlKFKCIiUoUoIi9Q/iHV+K8gSmCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7feec0de4610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "images_input = [[S.w[r + j * int(len(G))]\n",
    "         for j in np.arange(len(P))] \n",
    "         for r in np.arange(len(G))]\n",
    "images_input = np.array(images_input).reshape(int(n_hidden), int(n_input_width), int(n_input_height))\n",
    "\n",
    "\n",
    "k=1\n",
    "figure('input Weight visualisation', figsize=(5,5))\n",
    "for image in images_input:\n",
    "    subplot(3, 1, k)\n",
    "    imshow(image, cmap='winter', interpolation='None')\n",
    "    axis('off')\n",
    "\n",
    "    k+=1\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import animation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.animation as animation\n",
    "import math\n",
    "global_j=0\n",
    "global_jmax=0\n",
    "global_step = 25\n",
    "def animate_weights(G,P,StateMonitorS,end=10000,start=0,save=True,show=True,step = 25):\n",
    "    print n_hidden\n",
    "    \"\"\"\n",
    "    show(bool) : whether to show\n",
    "    save(bool) : whether to save\n",
    "    start(int) : start tick\n",
    "    end(int) : end tick\n",
    "    P,G : Neuron groups. Visualising weights from P to G\n",
    "    StateMonitorS : brian state monitor adjusted to weights you want to visualise\n",
    "    global_step(int) :global ticks from frame to next frame\n",
    "    global_j(int) : global counter\n",
    "    global_jmax : global, set to math.floor((end-start)/global_step) inside\n",
    "    \"\"\"\n",
    "    #step = 25\n",
    "    global global_step\n",
    "    global_step = step\n",
    "    def frames_generator(G,P,StateMonitorS,step=global_step,end=10000,start=0):\n",
    "        '''\n",
    "        generator for speed(hope it helps)\n",
    "        '''\n",
    "        #Reshape all weights as input images and put them all into one array.\n",
    "        toanim = []\n",
    "        frame = start\n",
    "        while frame < end:#in range(start,end,step):\n",
    "            images_input = [[StateMonitorS.w[r + j * int(len(G))][frame]\n",
    "                     for j in range(len(P))] \n",
    "                     for r in range(len(G))]\n",
    "            images_input = np.array(images_input).reshape(int(n_hidden), int(n_input_width), int(n_input_height))\n",
    "            together = np.hstack((images_input[0],np.ones((images_input[0].shape[0],1))*(np.nan),images_input[1],np.zeros((images_input[0].shape[0],1))*(np.nan),images_input[2]))\n",
    "            #toanim.append(together)\n",
    "            frame+=step\n",
    "            #if frame>\n",
    "            yield together\n",
    "\n",
    "\n",
    "    #Create animation\n",
    "    \n",
    "    #%matplotlib osx\n",
    "    global_j=0\n",
    "    global global_jmax\n",
    "    global_jmax = math.floor((end-start)/global_step)\n",
    "    def generate_data():\n",
    "        \"\"\"\n",
    "        awful piece of code\n",
    "        \"\"\"\n",
    "        #global toanim\n",
    "        global global_step\n",
    "        global global_j\n",
    "        global global_jmax\n",
    "        global_j+=1\n",
    "        if global_j>global_jmax:\n",
    "            global_j=global_jmax\n",
    "        for pic in frames_generator(G,P,StateMonitorS,step=global_step,end=end,start=global_j*global_step):\n",
    "            break\n",
    "        return pic#.reshape((8,8)) \n",
    "\n",
    "    def update(data):\n",
    "        mat.set_data(data)\n",
    "        return mat \n",
    "\n",
    "    #def data_gen():\n",
    "    #    while True:\n",
    "    #        yield frames_generator(G,P,StateMonitorS,step=25,end=10000,start=0)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    mat = ax.imshow(generate_data(),cmap=\"winter\",interpolation=\"none\")\n",
    "    plt.colorbar(mat)\n",
    "    ani = animation.FuncAnimation(fig, update, frames_generator(G,P,StateMonitorS,step=global_step,end=end,start=start), interval=10,\n",
    "                                  save_count=399)\n",
    "    #Show animation\n",
    "    if show:\n",
    "        plt.show()\n",
    "    if save:\n",
    "        #Saving animation as mp4 file\n",
    "        ani.save('MaWheightsAnimation.mp4',writer=animation.FFMpegFileWriter())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "animate_weights(G,P,StateMonitorS,save=False,step=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "z = S_neg.w\n",
    "for i in np.arange(int(len(G))):\n",
    "    z = insert(z, i+int(len(G))*i, 0)\n",
    "    \n",
    "images_out_neg = np.array(z).reshape(int(len(G)), 1, 2)\n",
    "\n",
    "k=1\n",
    "figure('negative weight visualisation', figsize=(5,5))\n",
    "for image in images_out_neg:\n",
    "    subplot(3, 3, k)\n",
    "    imshow(image, cmap='RdYlGn', interpolation='None')\n",
    "    axis('off')\n",
    "    \n",
    "    k+=1\n",
    "\n",
    "show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure('P_rates', figsize=(10,4))\n",
    "for k in np.arange(8):\n",
    "    plot(StateMonitorP.t/ms, StateMonitorP.rates[k], linewidth=1, label = str(k))\n",
    "legend(loc='best')\n",
    "show()\n",
    "\n",
    "#проверяем меняется ли вообще инпут (работает ли update_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure('P_a', figsize=(10,4))\n",
    "for k in np.arange(10):\n",
    "    plot(StateMonitorP.t/ms, StateMonitorP.a[k], linewidth=1, label = str(k))\n",
    "legend(loc='best')\n",
    "show()\n",
    "\n",
    "figure('P_ a-theta', figsize=(10,4))\n",
    "for k in np.arange(10):\n",
    "    plot(StateMonitorP.t/ms, StateMonitorP.diff[k], linewidth=1, label = str(k))\n",
    "legend(loc='best')\n",
    "show()\n",
    "\n",
    "figure('G_a', figsize=(10,4))\n",
    "for k in np.arange(len(G)):\n",
    "    plot(StateMonitorG.t/ms, StateMonitorG.a[k], linewidth=1, label = str(k))\n",
    "legend(loc='best')\n",
    "show()\n",
    "\n",
    "figure('G_hold', figsize=(10,4))\n",
    "for k in np.arange(len(G)):\n",
    "    plot(StateMonitorG.t/ms, StateMonitorG.hold[k], linewidth=1, label = str(k))\n",
    "legend(loc='best')\n",
    "show()\n",
    "\n",
    "figure('G_diff', figsize=(10,4))\n",
    "for k in np.arange(len(G)):\n",
    "    plot(StateMonitorG.t/ms, StateMonitorG.diff[k], linewidth=1, label = str(k))\n",
    "legend(loc='best')\n",
    "show()\n",
    "\n",
    "# #проверяем активность нейронов разных слоев (меняется ли она вообще?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure('G_I', figsize=(10,4))\n",
    "for k in np.arange(len(G)):\n",
    "    plot(StateMonitorG.t/ms, StateMonitorG.I_inp[k], linewidth=1, label = 'inp' + str(k))\n",
    "    plot(StateMonitorG.t/ms, StateMonitorG.I_neg[k], linewidth=1, label = 'neg' + str(k))\n",
    "legend(loc='best')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure('input weights', figsize=(10,4))\n",
    "for k in np.arange(10):\n",
    "    plot(StateMonitorS.t/ms, StateMonitorS.w[k], linewidth=1, label = str(k))\n",
    "#legend(loc='best')\n",
    "show()\n",
    "\n",
    "#проверяем есть ли какие-то аномалии в изменении весов нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure('negative intr weights', figsize=(10,4))\n",
    "for k in np.arange(len(S_neg)):\n",
    "    plot(StateMonitorS_neg.t/ms, StateMonitorS_neg.w[k], linewidth=1, label = str(k))\n",
    "legend(loc='best')\n",
    "show()\n",
    "\n",
    "#проверяем есть ли какие-то аномалии в изменении весов нейронов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#P.rates = np.zeros_like(P.rates)\n",
    "#G.I_teacher = np.zeros_like(G.I_teacher)\n",
    "predictions = []\n",
    "labels = []\n",
    "counter = 0\n",
    "train = 0\n",
    "\n",
    "run(20000*ms)\n",
    "\n",
    "#add last prediction\n",
    "#predictions.append(np.argmax(np.mean(StateMonitorG.a[:,-50:], axis=1)))\n",
    "\n",
    "print accuracy_score(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.argmax(np.mean(StateMonitorG.a[:,-50:], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figure('G_a_test', figsize=(10,4))\n",
    "for k in np.arange(len(G)):\n",
    "    plot(StateMonitorG.t/ms, StateMonitorG.a[k], linewidth=1, label = str(k))\n",
    "legend(loc='best')\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "images_input = [[S.w[r + j * int(len(G))]\n",
    "         for j in np.arange(len(P))] \n",
    "         for r in np.arange(len(G))]\n",
    "images_input = np.array(images_input).reshape(int(n_hidden), int(n_input_width), int(n_input_height))\n",
    "\n",
    "\n",
    "k=1\n",
    "figure('input Weight visualisation test', figsize=(5,5))\n",
    "for image in images_input:\n",
    "    subplot(3, 1, k)\n",
    "    imshow(image, cmap='winter', interpolation='None')\n",
    "    axis('off')\n",
    "\n",
    "    k+=1\n",
    "\n",
    "show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
